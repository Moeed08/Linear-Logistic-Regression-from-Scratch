{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRwtHGI8eENs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file=pd.read_csv('/content/vehicle.csv')\n",
        "cars_df=pd.DataFrame(file)\n",
        "cars_df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3psz-TNOeb9r",
        "outputId": "806ac3e0-ca8c-4176-8a64-4d8aefad7c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(846, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cars_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74wynG87etdJ",
        "outputId": "74657b78-338b-4d10-e51c-de51bb95a46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compactness                    0\n",
            "circularity                    5\n",
            "distance_circularity           4\n",
            "radius_ratio                   6\n",
            "pr.axis_aspect_ratio           2\n",
            "max.length_aspect_ratio        0\n",
            "scatter_ratio                  1\n",
            "elongatedness                  1\n",
            "pr.axis_rectangularity         3\n",
            "max.length_rectangularity      0\n",
            "scaled_variance                3\n",
            "scaled_variance.1              2\n",
            "scaled_radius_of_gyration      2\n",
            "scaled_radius_of_gyration.1    4\n",
            "skewness_about                 6\n",
            "skewness_about.1               1\n",
            "skewness_about.2               1\n",
            "hollows_ratio                  0\n",
            "class                          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cars_df = cars_df.dropna()\n",
        "cars_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dfmdou7fGjv",
        "outputId": "3f8b3438-8cbf-4e83-a99a-b2b002b1d909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(813, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "columns_to_scale = cars_df.columns.difference(['class'])  # excluding 'class'\n",
        "\n",
        "# Apply manual min-max normalization to each column\n",
        "for column in columns_to_scale:\n",
        "    min_value = cars_df[column].min()\n",
        "    max_value = cars_df[column].max()\n",
        "\n",
        "    # Apply the Min-Max normalization formula\n",
        "    cars_df[column] = (cars_df[column] - min_value) / (max_value - min_value)\n",
        "\n",
        "print(cars_df.head())\n",
        "print(cars_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duIlvcgQgI_R",
        "outputId": "75352c12-1320-473c-abca-01386b46ced0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   compactness  circularity  distance_circularity  radius_ratio  \\\n",
            "0     0.478261     0.576923              0.597222      0.323144   \n",
            "1     0.391304     0.307692              0.611111      0.161572   \n",
            "2     0.673913     0.653846              0.916667      0.458515   \n",
            "3     0.434783     0.307692              0.583333      0.240175   \n",
            "4     0.260870     0.423077              0.416667      0.441048   \n",
            "\n",
            "   pr.axis_aspect_ratio  max.length_aspect_ratio  scatter_ratio  \\\n",
            "0              0.274725                 0.150943       0.326797   \n",
            "1              0.109890                 0.132075       0.241830   \n",
            "2              0.208791                 0.150943       0.620915   \n",
            "3              0.175824                 0.132075       0.209150   \n",
            "4              0.615385                 0.943396       0.241830   \n",
            "\n",
            "   elongatedness  pr.axis_rectangularity  max.length_rectangularity  \\\n",
            "0       0.457143                0.250000                   0.585714   \n",
            "1       0.542857                0.166667                   0.357143   \n",
            "2       0.171429                0.500000                   0.571429   \n",
            "3       0.571429                0.166667                   0.357143   \n",
            "4       0.542857                0.166667                   0.371429   \n",
            "\n",
            "   scaled_variance  scaled_variance.1  scaled_radius_of_gyration  \\\n",
            "0         0.242105           0.233813                   0.471698   \n",
            "1         0.210526           0.175060                   0.308176   \n",
            "2         0.489474           0.540767                   0.698113   \n",
            "3         0.157895           0.149880                   0.113208   \n",
            "4         0.584211           0.169065                   0.496855   \n",
            "\n",
            "   scaled_radius_of_gyration.1  skewness_about  skewness_about.1  \\\n",
            "0                     0.144737        0.272727          0.390244   \n",
            "1                     0.171053        0.409091          0.341463   \n",
            "2                     0.184211        0.636364          0.219512   \n",
            "3                     0.052632        0.272727          0.243902   \n",
            "4                     0.894737        0.409091          0.268293   \n",
            "\n",
            "   skewness_about.2  hollows_ratio class  \n",
            "0          0.366667       0.533333   van  \n",
            "1          0.433333       0.600000   van  \n",
            "2          0.400000       0.500000   car  \n",
            "3          0.766667       0.866667   van  \n",
            "4          0.133333       0.066667   bus  \n",
            "(813, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cars_df['shape_descriptor'] = cars_df['distance_circularity'] + cars_df['radius_ratio'] + cars_df['scatter_ratio']\n",
        "\n",
        "# Combine aspect ratio columns\n",
        "cars_df['aspect_ratio'] = (cars_df['pr.axis_aspect_ratio'] + cars_df['max.length_aspect_ratio']) / 2\n",
        "\n",
        "# Combine rectangularity columns\n",
        "cars_df['rectangularity'] = (cars_df['pr.axis_rectangularity'] + cars_df['max.length_rectangularity']) / 2\n",
        "\n",
        "# Combine scaled variance columns\n",
        "cars_df['variance'] = (cars_df['scaled_variance'] + cars_df['scaled_variance.1']) / 2\n",
        "\n",
        "# Combine scaled radius of gyration columns\n",
        "cars_df['radius_of_gyration'] = (cars_df['scaled_radius_of_gyration'] + cars_df['scaled_radius_of_gyration.1']) / 2\n",
        "\n",
        "# Combine skewness columns\n",
        "cars_df['skewness'] = (cars_df['skewness_about'] + cars_df['skewness_about.1'] + cars_df['skewness_about.2']) / 3\n",
        "\n",
        "# Drop original columns that have been combined (optional)\n",
        "cars_df = cars_df.drop(['distance_circularity', 'radius_ratio', 'scatter_ratio',\n",
        "                        'pr.axis_aspect_ratio', 'max.length_aspect_ratio',\n",
        "                        'pr.axis_rectangularity', 'max.length_rectangularity',\n",
        "                        'scaled_variance', 'scaled_variance.1',\n",
        "                        'scaled_radius_of_gyration', 'scaled_radius_of_gyration.1',\n",
        "                        'skewness_about', 'skewness_about.1', 'skewness_about.2'], axis=1)\n",
        "\n",
        "# Display the DataFrame after feature engineering\n",
        "print(cars_df.head())\n",
        "print(cars_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz-_v8cLjYfy",
        "outputId": "2b5446ee-3bef-4854-a250-c5121d53a2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   compactness  circularity  elongatedness  hollows_ratio class  \\\n",
            "0     0.478261     0.576923       0.457143       0.533333   van   \n",
            "1     0.391304     0.307692       0.542857       0.600000   van   \n",
            "2     0.673913     0.653846       0.171429       0.500000   car   \n",
            "3     0.434783     0.307692       0.571429       0.866667   van   \n",
            "4     0.260870     0.423077       0.542857       0.066667   bus   \n",
            "\n",
            "   shape_descriptor  aspect_ratio  rectangularity  variance  \\\n",
            "0          1.247164      0.212834        0.417857  0.237959   \n",
            "1          1.014513      0.120983        0.261905  0.192793   \n",
            "2          1.996097      0.179867        0.535714  0.515121   \n",
            "3          1.032658      0.153950        0.261905  0.153887   \n",
            "4          1.099545      0.779390        0.269048  0.376638   \n",
            "\n",
            "   radius_of_gyration  skewness  \n",
            "0            0.308217  0.343213  \n",
            "1            0.239614  0.394629  \n",
            "2            0.441162  0.418625  \n",
            "3            0.082920  0.427765  \n",
            "4            0.695796  0.270239  \n",
            "(813, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = cars_df.drop(columns=['class']).to_numpy()\n",
        "print(X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwZXpaoSlPBc",
        "outputId": "2f215de0-fe80-4047-c76a-43d64c6d85da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(813, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import numpy as np\n",
        "\n",
        "# Assume 'cars_df' is your DataFrame with the 'class' column containing textual data\n",
        "# Get unique classes and create a mapping from class labels to integers\n",
        "unique_classes = cars_df['class'].unique()\n",
        "class_to_int = {label: idx for idx, label in enumerate(unique_classes)}\n",
        "\n",
        "# Map class labels to integers\n",
        "Y = cars_df['class'].map(class_to_int).to_numpy()\n",
        "\n",
        "# Now Y is a 1D array of integers representing class labels\n",
        "print(Y)\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFTk4CwepFlE",
        "outputId": "8c834121-8ab8-4423-e2e1-278c9d81c258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 2 2 0 0 0 1 2 0 2 1 0 2 1 2 0 2 2 1 0 1 1 2 1 0 1 1 1 1 2 0 1 2 1\n",
            " 0 0 1 1 0 0 2 0 1 1 1 1 2 2 0 1 0 1 0 1 1 0 2 2 1 1 0 2 1 1 1 0 1 1 2 2 2\n",
            " 0 1 2 2 0 0 2 1 1 1 1 0 2 1 1 2 1 2 2 0 0 0 2 1 1 2 2 0 0 1 1 0 0 1 1 2 1\n",
            " 0 0 1 0 0 2 2 0 2 1 1 1 0 1 0 0 0 1 0 1 1 2 1 1 0 2 1 0 1 2 1 1 0 2 1 0 1\n",
            " 1 1 1 1 1 1 1 1 2 0 1 2 0 2 0 2 1 2 0 1 1 2 1 1 2 2 1 1 1 1 0 2 1 2 1 2 2\n",
            " 2 0 1 1 1 0 0 1 2 1 1 0 2 2 1 1 1 2 0 1 0 2 1 0 1 0 1 1 0 1 2 1 0 0 2 1 2\n",
            " 1 1 2 1 0 0 2 1 1 0 1 0 2 0 1 1 1 1 1 1 1 0 0 1 2 1 0 0 2 1 0 2 2 2 1 1 2\n",
            " 1 2 2 1 0 2 1 1 0 0 2 0 2 2 2 1 1 2 1 1 2 0 2 2 1 1 1 1 0 2 1 2 0 0 1 0 1\n",
            " 2 2 1 1 2 1 1 0 0 1 1 2 2 1 0 2 0 2 2 1 1 1 1 1 1 0 1 1 1 0 2 1 1 2 1 1 1\n",
            " 1 1 1 0 1 1 0 1 2 1 2 2 2 0 2 1 1 1 1 1 2 2 1 1 0 1 0 0 1 2 0 0 2 1 1 2 2\n",
            " 0 1 1 1 0 1 2 1 1 2 1 1 1 2 1 0 1 2 2 2 0 1 1 2 1 1 1 1 1 0 1 2 1 2 1 0 0\n",
            " 1 1 1 1 0 0 1 2 0 1 1 2 0 2 1 1 2 1 2 0 0 1 1 0 1 1 1 2 2 2 1 0 0 1 2 1 1\n",
            " 1 1 0 2 2 1 1 1 0 0 2 1 1 1 1 1 1 2 1 2 2 0 0 1 1 1 1 1 1 1 1 1 0 1 2 1 1\n",
            " 1 0 1 1 1 1 0 1 0 0 1 1 1 1 2 2 1 2 1 0 0 0 1 0 1 2 2 0 1 1 2 0 0 2 2 1 0\n",
            " 1 1 2 1 1 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 1 0 0 1 1 1 1 1 1 2 0 1 1 2 0 1 1\n",
            " 1 1 2 1 2 1 0 1 1 0 2 1 2 0 1 1 1 1 0 0 1 2 1 0 1 2 1 1 1 0 0 1 1 0 1 1 1\n",
            " 1 2 2 2 0 1 1 2 1 1 0 1 2 2 1 1 2 1 2 0 1 2 1 1 1 1 1 1 1 1 0 2 0 0 1 0 1\n",
            " 1 1 0 0 1 1 0 2 1 1 2 1 1 1 2 2 2 2 0 2 0 2 2 2 1 2 1 1 1 2 1 0 1 0 1 2 2\n",
            " 1 1 1 1 0 1 1 0 0 0 1 2 1 1 1 2 1 1 2 1 1 1 1 0 1 0 0 1 2 1 1 1 2 0 2 0 1\n",
            " 1 2 2 0 1 2 1 1 0 2 0 2 0 1 1 0 2 1 0 0 1 1 2 0 1 1 0 1 1 2 1 2 1 1 2 1 1\n",
            " 2 0 2 1 2 1 0 1 0 1 1 0 2 1 0 1 1 2 0 1 2 2 0 1 1 1 2 0 1 1 2 1 2 1 1 2 1\n",
            " 1 1 2 0 2 2 0 1 1 1 1 1 0 1 1 1 1 1 0 0 2 2 1 1 1 2 0 1 0 0 1 1 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, alpha=0.01, max_iters=None, threshold=1e-5):\n",
        "        self.weights = None\n",
        "        self.alpha = alpha\n",
        "        self.max_iters = max_iters\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))  # Sigmoid function\n",
        "\n",
        "    def loss(self, h, y):\n",
        "        return -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))  # Logistic loss function\n",
        "\n",
        "    def Train(self, X, Y, alpha=0.01, max_iters=None, print_loss_iter=100):\n",
        "        self.alpha = alpha\n",
        "        m, n = X.shape\n",
        "        self.weights = np.zeros(n)\n",
        "        self.max_iters = max_iters\n",
        "        prev_loss = np.inf\n",
        "\n",
        "        if max_iters is None:\n",
        "            epoch = 0\n",
        "            while True:\n",
        "                z = np.dot(X, self.weights)\n",
        "                h = self.sigmoid(z)\n",
        "                loss = self.loss(h, Y)\n",
        "\n",
        "                gradient = np.dot(X.T, (h - Y)) / m\n",
        "                self.weights -= self.alpha * gradient\n",
        "\n",
        "                if epoch % print_loss_iter == 0:\n",
        "                    print(f\"Iteration {epoch}: Loss = {loss}\")\n",
        "\n",
        "                if abs(prev_loss - loss) < self.threshold:\n",
        "                    break\n",
        "\n",
        "                prev_loss = loss\n",
        "                epoch += 1\n",
        "        else:\n",
        "            # Training with a fixed number of iterations\n",
        "            for epoch in range(max_iters):\n",
        "                z = np.dot(X, self.weights)\n",
        "                h = self.sigmoid(z)\n",
        "                loss = self.loss(h, Y)\n",
        "\n",
        "                # Update weights using gradient descent\n",
        "                gradient = np.dot(X.T, (h - Y)) / m\n",
        "                self.weights -= self.alpha * gradient\n",
        "\n",
        "                if epoch % print_loss_iter == 0:\n",
        "                    print(f\"Iteration {epoch}: Loss = {loss}\")\n",
        "\n",
        "    def Predict_Class(self, X):\n",
        "        z = np.dot(X, self.weights)\n",
        "        h = self.sigmoid(z)\n",
        "        return np.where(h >= 0.5, 1, 0)  # Predict class based on threshold 0.5\n",
        "\n",
        "    def Predict_Confidence(self, X):\n",
        "        z = np.dot(X, self.weights)\n",
        "        h = self.sigmoid(z)\n",
        "        return h  # Return the probabilities (confidence scores)\n",
        "\n",
        "    def Get_Weights(self):\n",
        "        return self.weights  # Return model weights\n",
        "\n",
        "class OneVsAllLogisticRegression:\n",
        "    def __init__(self, num_classes=4, alpha=0.01, max_iters=None, threshold=1e-5):\n",
        "        self.num_classes = num_classes\n",
        "        self.models = [LogisticRegression(alpha, max_iters, threshold) for _ in range(num_classes)]\n",
        "\n",
        "    def Train(self, X, Y, alpha=0.01, max_iters=None, print_loss_iter=100):\n",
        "        for i in range(self.num_classes):\n",
        "            print(f\"Training classifier for class {i} vs all...\")\n",
        "            Y_binary = np.where(Y == i, 1, 0)\n",
        "            self.models[i].Train(X, Y_binary, alpha, max_iters, print_loss_iter)\n",
        "\n",
        "    def Predict_Class(self, X):\n",
        "        confidence_scores = np.zeros((X.shape[0], self.num_classes))\n",
        "        for i in range(self.num_classes):\n",
        "            confidence_scores[:, i] = self.models[i].Predict_Confidence(X)  # Get confidence for each class\n",
        "\n",
        "        return np.argmax(confidence_scores, axis=1)\n",
        "\n",
        "    def Get_Weights(self):\n",
        "        return [model.Get_Weights() for model in self.models]\n",
        "\n",
        "unique_classes = cars_df['class'].unique()\n",
        "class_to_int = {label: idx for idx, label in enumerate(unique_classes)}\n",
        "Y = cars_df['class'].map(class_to_int).to_numpy()  # Convert classes to integers\n",
        "\n",
        "X = cars_df.drop(columns=['class']).to_numpy()\n",
        "\n",
        "num_classes = len(unique_classes)\n",
        "\n",
        "ova_lr = OneVsAllLogisticRegression(num_classes=num_classes, alpha=0.01, max_iters=1000, threshold=1e-5)\n",
        "\n",
        "ova_lr.Train(X, Y, alpha=0.01, max_iters=1000, print_loss_iter=100)\n",
        "\n",
        "Y_pred = ova_lr.Predict_Class(X)\n",
        "\n",
        "accuracy = np.mean(Y_pred == Y)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "weights = ova_lr.Get_Weights()\n",
        "print(\"Model weights for each class:\", weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npXJ1I4urJ7y",
        "outputId": "3c2089e0-6518-49d6-b06b-49d6989edfdf"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier for class 0 vs all...\n",
            "Iteration 0: Loss = 0.6931471805599452\n",
            "Iteration 100: Loss = 0.5493295378566357\n",
            "Iteration 200: Loss = 0.5117132637219841\n",
            "Iteration 300: Loss = 0.49818302283253385\n",
            "Iteration 400: Loss = 0.4916471466666432\n",
            "Iteration 500: Loss = 0.48753896461019897\n",
            "Iteration 600: Loss = 0.4844011513372349\n",
            "Iteration 700: Loss = 0.4817123241918736\n",
            "Iteration 800: Loss = 0.4792703599318234\n",
            "Iteration 900: Loss = 0.4769912951610611\n",
            "Training classifier for class 1 vs all...\n",
            "Iteration 0: Loss = 0.6931471805599452\n",
            "Iteration 100: Loss = 0.6787078635689118\n",
            "Iteration 200: Loss = 0.6718101979891401\n",
            "Iteration 300: Loss = 0.6667139404970499\n",
            "Iteration 400: Loss = 0.6622195490231287\n",
            "Iteration 500: Loss = 0.6580583131583269\n",
            "Iteration 600: Loss = 0.6541577381988778\n",
            "Iteration 700: Loss = 0.6504883156575503\n",
            "Iteration 800: Loss = 0.6470308645135593\n",
            "Iteration 900: Loss = 0.6437694312852794\n",
            "Training classifier for class 2 vs all...\n",
            "Iteration 0: Loss = 0.6931471805599452\n",
            "Iteration 100: Loss = 0.5894741842086512\n",
            "Iteration 200: Loss = 0.5634315065545004\n",
            "Iteration 300: Loss = 0.554808469154348\n",
            "Iteration 400: Loss = 0.5509038061030143\n",
            "Iteration 500: Loss = 0.5484733231923649\n",
            "Iteration 600: Loss = 0.5465697292756007\n",
            "Iteration 700: Loss = 0.544892365540167\n",
            "Iteration 800: Loss = 0.5433397601829265\n",
            "Iteration 900: Loss = 0.541875151371632\n",
            "Accuracy: 51.05%\n",
            "Model weights for each class: [array([-0.15671336, -0.20759737,  0.19712292, -0.02435426, -0.82202543,\n",
            "        0.00411403, -0.18777056, -0.2912683 , -0.14065635, -0.11270788]), array([ 0.01155874, -0.04732092, -0.51280765,  0.05485255,  0.35226384,\n",
            "       -0.08384806,  0.03485138,  0.10250943, -0.15588571,  0.02051281]), array([-0.20988633, -0.07166823, -0.32003437, -0.45277322, -0.41243021,\n",
            "       -0.04921357, -0.08811347, -0.00197512,  0.02863142, -0.23291292])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1\n"
      ],
      "metadata": {
        "id": "GVYFIyFlypOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file=pd.read_csv('/content/advertising.csv')\n",
        "print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmaGJU4LyyD_",
        "outputId": "3965ffc9-6244-4934-f455-f46a73f5f17c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        TV  Radio  Newspaper  Sales\n",
            "0    230.1   37.8       69.2   22.1\n",
            "1     44.5   39.3       45.1   10.4\n",
            "2     17.2   45.9       69.3   12.0\n",
            "3    151.5   41.3       58.5   16.5\n",
            "4    180.8   10.8       58.4   17.9\n",
            "..     ...    ...        ...    ...\n",
            "195   38.2    3.7       13.8    7.6\n",
            "196   94.2    4.9        8.1   14.0\n",
            "197  177.0    9.3        6.4   14.8\n",
            "198  283.6   42.0       66.2   25.5\n",
            "199  232.1    8.6        8.7   18.4\n",
            "\n",
            "[200 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=np.array(file)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6z2znRky8BZ",
        "outputId": "0900682f-9350-499a-bd2f-d56aa8a82d50"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[230.1  37.8  69.2  22.1]\n",
            " [ 44.5  39.3  45.1  10.4]\n",
            " [ 17.2  45.9  69.3  12. ]\n",
            " [151.5  41.3  58.5  16.5]\n",
            " [180.8  10.8  58.4  17.9]\n",
            " [  8.7  48.9  75.    7.2]\n",
            " [ 57.5  32.8  23.5  11.8]\n",
            " [120.2  19.6  11.6  13.2]\n",
            " [  8.6   2.1   1.    4.8]\n",
            " [199.8   2.6  21.2  15.6]\n",
            " [ 66.1   5.8  24.2  12.6]\n",
            " [214.7  24.    4.   17.4]\n",
            " [ 23.8  35.1  65.9   9.2]\n",
            " [ 97.5   7.6   7.2  13.7]\n",
            " [204.1  32.9  46.   19. ]\n",
            " [195.4  47.7  52.9  22.4]\n",
            " [ 67.8  36.6 114.   12.5]\n",
            " [281.4  39.6  55.8  24.4]\n",
            " [ 69.2  20.5  18.3  11.3]\n",
            " [147.3  23.9  19.1  14.6]\n",
            " [218.4  27.7  53.4  18. ]\n",
            " [237.4   5.1  23.5  17.5]\n",
            " [ 13.2  15.9  49.6   5.6]\n",
            " [228.3  16.9  26.2  20.5]\n",
            " [ 62.3  12.6  18.3   9.7]\n",
            " [262.9   3.5  19.5  17. ]\n",
            " [142.9  29.3  12.6  15. ]\n",
            " [240.1  16.7  22.9  20.9]\n",
            " [248.8  27.1  22.9  18.9]\n",
            " [ 70.6  16.   40.8  10.5]\n",
            " [292.9  28.3  43.2  21.4]\n",
            " [112.9  17.4  38.6  11.9]\n",
            " [ 97.2   1.5  30.   13.2]\n",
            " [265.6  20.    0.3  17.4]\n",
            " [ 95.7   1.4   7.4  11.9]\n",
            " [290.7   4.1   8.5  17.8]\n",
            " [266.9  43.8   5.   25.4]\n",
            " [ 74.7  49.4  45.7  14.7]\n",
            " [ 43.1  26.7  35.1  10.1]\n",
            " [228.   37.7  32.   21.5]\n",
            " [202.5  22.3  31.6  16.6]\n",
            " [177.   33.4  38.7  17.1]\n",
            " [293.6  27.7   1.8  20.7]\n",
            " [206.9   8.4  26.4  17.9]\n",
            " [ 25.1  25.7  43.3   8.5]\n",
            " [175.1  22.5  31.5  16.1]\n",
            " [ 89.7   9.9  35.7  10.6]\n",
            " [239.9  41.5  18.5  23.2]\n",
            " [227.2  15.8  49.9  19.8]\n",
            " [ 66.9  11.7  36.8   9.7]\n",
            " [199.8   3.1  34.6  16.4]\n",
            " [100.4   9.6   3.6  10.7]\n",
            " [216.4  41.7  39.6  22.6]\n",
            " [182.6  46.2  58.7  21.2]\n",
            " [262.7  28.8  15.9  20.2]\n",
            " [198.9  49.4  60.   23.7]\n",
            " [  7.3  28.1  41.4   5.5]\n",
            " [136.2  19.2  16.6  13.2]\n",
            " [210.8  49.6  37.7  23.8]\n",
            " [210.7  29.5   9.3  18.4]\n",
            " [ 53.5   2.   21.4   8.1]\n",
            " [261.3  42.7  54.7  24.2]\n",
            " [239.3  15.5  27.3  20.7]\n",
            " [102.7  29.6   8.4  14. ]\n",
            " [131.1  42.8  28.9  16. ]\n",
            " [ 69.    9.3   0.9  11.3]\n",
            " [ 31.5  24.6   2.2  11. ]\n",
            " [139.3  14.5  10.2  13.4]\n",
            " [237.4  27.5  11.   18.9]\n",
            " [216.8  43.9  27.2  22.3]\n",
            " [199.1  30.6  38.7  18.3]\n",
            " [109.8  14.3  31.7  12.4]\n",
            " [ 26.8  33.   19.3   8.8]\n",
            " [129.4   5.7  31.3  11. ]\n",
            " [213.4  24.6  13.1  17. ]\n",
            " [ 16.9  43.7  89.4   8.7]\n",
            " [ 27.5   1.6  20.7   6.9]\n",
            " [120.5  28.5  14.2  14.2]\n",
            " [  5.4  29.9   9.4   5.3]\n",
            " [116.    7.7  23.1  11. ]\n",
            " [ 76.4  26.7  22.3  11.8]\n",
            " [239.8   4.1  36.9  17.3]\n",
            " [ 75.3  20.3  32.5  11.3]\n",
            " [ 68.4  44.5  35.6  13.6]\n",
            " [213.5  43.   33.8  21.7]\n",
            " [193.2  18.4  65.7  20.2]\n",
            " [ 76.3  27.5  16.   12. ]\n",
            " [110.7  40.6  63.2  16. ]\n",
            " [ 88.3  25.5  73.4  12.9]\n",
            " [109.8  47.8  51.4  16.7]\n",
            " [134.3   4.9   9.3  14. ]\n",
            " [ 28.6   1.5  33.    7.3]\n",
            " [217.7  33.5  59.   19.4]\n",
            " [250.9  36.5  72.3  22.2]\n",
            " [107.4  14.   10.9  11.5]\n",
            " [163.3  31.6  52.9  16.9]\n",
            " [197.6   3.5   5.9  16.7]\n",
            " [184.9  21.   22.   20.5]\n",
            " [289.7  42.3  51.2  25.4]\n",
            " [135.2  41.7  45.9  17.2]\n",
            " [222.4   4.3  49.8  16.7]\n",
            " [296.4  36.3 100.9  23.8]\n",
            " [280.2  10.1  21.4  19.8]\n",
            " [187.9  17.2  17.9  19.7]\n",
            " [238.2  34.3   5.3  20.7]\n",
            " [137.9  46.4  59.   15. ]\n",
            " [ 25.   11.   29.7   7.2]\n",
            " [ 90.4   0.3  23.2  12. ]\n",
            " [ 13.1   0.4  25.6   5.3]\n",
            " [255.4  26.9   5.5  19.8]\n",
            " [225.8   8.2  56.5  18.4]\n",
            " [241.7  38.   23.2  21.8]\n",
            " [175.7  15.4   2.4  17.1]\n",
            " [209.6  20.6  10.7  20.9]\n",
            " [ 78.2  46.8  34.5  14.6]\n",
            " [ 75.1  35.   52.7  12.6]\n",
            " [139.2  14.3  25.6  12.2]\n",
            " [ 76.4   0.8  14.8   9.4]\n",
            " [125.7  36.9  79.2  15.9]\n",
            " [ 19.4  16.   22.3   6.6]\n",
            " [141.3  26.8  46.2  15.5]\n",
            " [ 18.8  21.7  50.4   7. ]\n",
            " [224.    2.4  15.6  16.6]\n",
            " [123.1  34.6  12.4  15.2]\n",
            " [229.5  32.3  74.2  19.7]\n",
            " [ 87.2  11.8  25.9  10.6]\n",
            " [  7.8  38.9  50.6   6.6]\n",
            " [ 80.2   0.    9.2  11.9]\n",
            " [220.3  49.    3.2  24.7]\n",
            " [ 59.6  12.   43.1   9.7]\n",
            " [  0.7  39.6   8.7   1.6]\n",
            " [265.2   2.9  43.   17.7]\n",
            " [  8.4  27.2   2.1   5.7]\n",
            " [219.8  33.5  45.1  19.6]\n",
            " [ 36.9  38.6  65.6  10.8]\n",
            " [ 48.3  47.    8.5  11.6]\n",
            " [ 25.6  39.    9.3   9.5]\n",
            " [273.7  28.9  59.7  20.8]\n",
            " [ 43.   25.9  20.5   9.6]\n",
            " [184.9  43.9   1.7  20.7]\n",
            " [ 73.4  17.   12.9  10.9]\n",
            " [193.7  35.4  75.6  19.2]\n",
            " [220.5  33.2  37.9  20.1]\n",
            " [104.6   5.7  34.4  10.4]\n",
            " [ 96.2  14.8  38.9  12.3]\n",
            " [140.3   1.9   9.   10.3]\n",
            " [240.1   7.3   8.7  18.2]\n",
            " [243.2  49.   44.3  25.4]\n",
            " [ 38.   40.3  11.9  10.9]\n",
            " [ 44.7  25.8  20.6  10.1]\n",
            " [280.7  13.9  37.   16.1]\n",
            " [121.    8.4  48.7  11.6]\n",
            " [197.6  23.3  14.2  16.6]\n",
            " [171.3  39.7  37.7  16. ]\n",
            " [187.8  21.1   9.5  20.6]\n",
            " [  4.1  11.6   5.7   3.2]\n",
            " [ 93.9  43.5  50.5  15.3]\n",
            " [149.8   1.3  24.3  10.1]\n",
            " [ 11.7  36.9  45.2   7.3]\n",
            " [131.7  18.4  34.6  12.9]\n",
            " [172.5  18.1  30.7  16.4]\n",
            " [ 85.7  35.8  49.3  13.3]\n",
            " [188.4  18.1  25.6  19.9]\n",
            " [163.5  36.8   7.4  18. ]\n",
            " [117.2  14.7   5.4  11.9]\n",
            " [234.5   3.4  84.8  16.9]\n",
            " [ 17.9  37.6  21.6   8. ]\n",
            " [206.8   5.2  19.4  17.2]\n",
            " [215.4  23.6  57.6  17.1]\n",
            " [284.3  10.6   6.4  20. ]\n",
            " [ 50.   11.6  18.4   8.4]\n",
            " [164.5  20.9  47.4  17.5]\n",
            " [ 19.6  20.1  17.    7.6]\n",
            " [168.4   7.1  12.8  16.7]\n",
            " [222.4   3.4  13.1  16.5]\n",
            " [276.9  48.9  41.8  27. ]\n",
            " [248.4  30.2  20.3  20.2]\n",
            " [170.2   7.8  35.2  16.7]\n",
            " [276.7   2.3  23.7  16.8]\n",
            " [165.6  10.   17.6  17.6]\n",
            " [156.6   2.6   8.3  15.5]\n",
            " [218.5   5.4  27.4  17.2]\n",
            " [ 56.2   5.7  29.7   8.7]\n",
            " [287.6  43.   71.8  26.2]\n",
            " [253.8  21.3  30.   17.6]\n",
            " [205.   45.1  19.6  22.6]\n",
            " [139.5   2.1  26.6  10.3]\n",
            " [191.1  28.7  18.2  17.3]\n",
            " [286.   13.9   3.7  20.9]\n",
            " [ 18.7  12.1  23.4   6.7]\n",
            " [ 39.5  41.1   5.8  10.8]\n",
            " [ 75.5  10.8   6.   11.9]\n",
            " [ 17.2   4.1  31.6   5.9]\n",
            " [166.8  42.    3.6  19.6]\n",
            " [149.7  35.6   6.   17.3]\n",
            " [ 38.2   3.7  13.8   7.6]\n",
            " [ 94.2   4.9   8.1  14. ]\n",
            " [177.    9.3   6.4  14.8]\n",
            " [283.6  42.   66.2  25.5]\n",
            " [232.1   8.6   8.7  18.4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "file = pd.read_csv('/content/advertising.csv')\n",
        "print(file)\n",
        "\n",
        "# Convert to numpy array\n",
        "data = np.array(file)\n",
        "print(data)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data[:, :-1]  # All columns except the last\n",
        "Y = data[:, -1]   # Only the last column\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "# Feature scaling\n",
        "X = X.astype(float)  # Convert to float for mathematical operations\n",
        "X_max = X.max(axis=0)\n",
        "X_max[X_max == 0] = 1  # Avoid division by zero\n",
        "X = X / X_max\n",
        "print(X)\n",
        "print(X.shape)\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self, alpha=0.01, max_iters=None, threshold=1e-6):\n",
        "        self.alpha = alpha\n",
        "        self.max_iters = max_iters\n",
        "        self.threshold = threshold\n",
        "        self.weights = None\n",
        "\n",
        "    def initializeWeights(self, n_features):\n",
        "        self.weights = np.random.rand(n_features)\n",
        "\n",
        "    def loss(self, X, Y):\n",
        "        predictions = np.dot(X, self.weights)\n",
        "        errors = predictions - Y\n",
        "        mse = np.mean(errors ** 2)\n",
        "        return mse\n",
        "\n",
        "    def gradientDescent(self, X, Y):\n",
        "        n_samples = X.shape[0]\n",
        "        predictions = np.dot(X, self.weights)\n",
        "        errors = predictions - Y\n",
        "        gradient = (2 / n_samples) * np.dot(X.T, errors)\n",
        "        self.weights -= self.alpha * gradient\n",
        "\n",
        "    def Train(self, X, Y, alpha=0.01, max_iters=None, print_loss_iter=100):\n",
        "        self.alpha = alpha\n",
        "        self.max_iters = max_iters\n",
        "        n_samples, n_features = X.shape\n",
        "        self.initializeWeights(n_features)\n",
        "\n",
        "        prev_loss = float('inf')\n",
        "        epoch = 0\n",
        "\n",
        "        while epoch < (self.max_iters if self.max_iters else float('inf')):\n",
        "            epoch += 1\n",
        "            # Perform one step of gradient descent\n",
        "            self.gradientDescent(X, Y)\n",
        "\n",
        "            # Compute current loss\n",
        "            current_loss = self.loss(X, Y)\n",
        "\n",
        "            # Print loss if required\n",
        "            if epoch % print_loss_iter == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {current_loss}')\n",
        "\n",
        "            # Check for stopping criteria\n",
        "            loss_change = abs(prev_loss - current_loss)\n",
        "            if self.max_iters is None and loss_change < self.threshold:\n",
        "                print(f'Stopping at epoch {epoch}, Loss: {current_loss}, Change in loss: {loss_change}')\n",
        "                break\n",
        "\n",
        "            prev_loss = current_loss\n",
        "\n",
        "    def Predict(self, X):\n",
        "        return np.dot(X, self.weights)\n",
        "\n",
        "    def Get_Weights(self):\n",
        "        return self.weights\n",
        "\n",
        "\n",
        "model = LinearRegression(alpha=0.01, max_iters=1000)\n",
        "model.Train(X, Y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.Predict(X)\n",
        "print(predictions)\n",
        "\n",
        "# Get model weights\n",
        "weights = model.Get_Weights()\n",
        "print(weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBFmOMySy-kQ",
        "outputId": "ac31f942-c386-43f5-d7c8-51d65916e5de"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        TV  Radio  Newspaper  Sales\n",
            "0    230.1   37.8       69.2   22.1\n",
            "1     44.5   39.3       45.1   10.4\n",
            "2     17.2   45.9       69.3   12.0\n",
            "3    151.5   41.3       58.5   16.5\n",
            "4    180.8   10.8       58.4   17.9\n",
            "..     ...    ...        ...    ...\n",
            "195   38.2    3.7       13.8    7.6\n",
            "196   94.2    4.9        8.1   14.0\n",
            "197  177.0    9.3        6.4   14.8\n",
            "198  283.6   42.0       66.2   25.5\n",
            "199  232.1    8.6        8.7   18.4\n",
            "\n",
            "[200 rows x 4 columns]\n",
            "[[230.1  37.8  69.2  22.1]\n",
            " [ 44.5  39.3  45.1  10.4]\n",
            " [ 17.2  45.9  69.3  12. ]\n",
            " [151.5  41.3  58.5  16.5]\n",
            " [180.8  10.8  58.4  17.9]\n",
            " [  8.7  48.9  75.    7.2]\n",
            " [ 57.5  32.8  23.5  11.8]\n",
            " [120.2  19.6  11.6  13.2]\n",
            " [  8.6   2.1   1.    4.8]\n",
            " [199.8   2.6  21.2  15.6]\n",
            " [ 66.1   5.8  24.2  12.6]\n",
            " [214.7  24.    4.   17.4]\n",
            " [ 23.8  35.1  65.9   9.2]\n",
            " [ 97.5   7.6   7.2  13.7]\n",
            " [204.1  32.9  46.   19. ]\n",
            " [195.4  47.7  52.9  22.4]\n",
            " [ 67.8  36.6 114.   12.5]\n",
            " [281.4  39.6  55.8  24.4]\n",
            " [ 69.2  20.5  18.3  11.3]\n",
            " [147.3  23.9  19.1  14.6]\n",
            " [218.4  27.7  53.4  18. ]\n",
            " [237.4   5.1  23.5  17.5]\n",
            " [ 13.2  15.9  49.6   5.6]\n",
            " [228.3  16.9  26.2  20.5]\n",
            " [ 62.3  12.6  18.3   9.7]\n",
            " [262.9   3.5  19.5  17. ]\n",
            " [142.9  29.3  12.6  15. ]\n",
            " [240.1  16.7  22.9  20.9]\n",
            " [248.8  27.1  22.9  18.9]\n",
            " [ 70.6  16.   40.8  10.5]\n",
            " [292.9  28.3  43.2  21.4]\n",
            " [112.9  17.4  38.6  11.9]\n",
            " [ 97.2   1.5  30.   13.2]\n",
            " [265.6  20.    0.3  17.4]\n",
            " [ 95.7   1.4   7.4  11.9]\n",
            " [290.7   4.1   8.5  17.8]\n",
            " [266.9  43.8   5.   25.4]\n",
            " [ 74.7  49.4  45.7  14.7]\n",
            " [ 43.1  26.7  35.1  10.1]\n",
            " [228.   37.7  32.   21.5]\n",
            " [202.5  22.3  31.6  16.6]\n",
            " [177.   33.4  38.7  17.1]\n",
            " [293.6  27.7   1.8  20.7]\n",
            " [206.9   8.4  26.4  17.9]\n",
            " [ 25.1  25.7  43.3   8.5]\n",
            " [175.1  22.5  31.5  16.1]\n",
            " [ 89.7   9.9  35.7  10.6]\n",
            " [239.9  41.5  18.5  23.2]\n",
            " [227.2  15.8  49.9  19.8]\n",
            " [ 66.9  11.7  36.8   9.7]\n",
            " [199.8   3.1  34.6  16.4]\n",
            " [100.4   9.6   3.6  10.7]\n",
            " [216.4  41.7  39.6  22.6]\n",
            " [182.6  46.2  58.7  21.2]\n",
            " [262.7  28.8  15.9  20.2]\n",
            " [198.9  49.4  60.   23.7]\n",
            " [  7.3  28.1  41.4   5.5]\n",
            " [136.2  19.2  16.6  13.2]\n",
            " [210.8  49.6  37.7  23.8]\n",
            " [210.7  29.5   9.3  18.4]\n",
            " [ 53.5   2.   21.4   8.1]\n",
            " [261.3  42.7  54.7  24.2]\n",
            " [239.3  15.5  27.3  20.7]\n",
            " [102.7  29.6   8.4  14. ]\n",
            " [131.1  42.8  28.9  16. ]\n",
            " [ 69.    9.3   0.9  11.3]\n",
            " [ 31.5  24.6   2.2  11. ]\n",
            " [139.3  14.5  10.2  13.4]\n",
            " [237.4  27.5  11.   18.9]\n",
            " [216.8  43.9  27.2  22.3]\n",
            " [199.1  30.6  38.7  18.3]\n",
            " [109.8  14.3  31.7  12.4]\n",
            " [ 26.8  33.   19.3   8.8]\n",
            " [129.4   5.7  31.3  11. ]\n",
            " [213.4  24.6  13.1  17. ]\n",
            " [ 16.9  43.7  89.4   8.7]\n",
            " [ 27.5   1.6  20.7   6.9]\n",
            " [120.5  28.5  14.2  14.2]\n",
            " [  5.4  29.9   9.4   5.3]\n",
            " [116.    7.7  23.1  11. ]\n",
            " [ 76.4  26.7  22.3  11.8]\n",
            " [239.8   4.1  36.9  17.3]\n",
            " [ 75.3  20.3  32.5  11.3]\n",
            " [ 68.4  44.5  35.6  13.6]\n",
            " [213.5  43.   33.8  21.7]\n",
            " [193.2  18.4  65.7  20.2]\n",
            " [ 76.3  27.5  16.   12. ]\n",
            " [110.7  40.6  63.2  16. ]\n",
            " [ 88.3  25.5  73.4  12.9]\n",
            " [109.8  47.8  51.4  16.7]\n",
            " [134.3   4.9   9.3  14. ]\n",
            " [ 28.6   1.5  33.    7.3]\n",
            " [217.7  33.5  59.   19.4]\n",
            " [250.9  36.5  72.3  22.2]\n",
            " [107.4  14.   10.9  11.5]\n",
            " [163.3  31.6  52.9  16.9]\n",
            " [197.6   3.5   5.9  16.7]\n",
            " [184.9  21.   22.   20.5]\n",
            " [289.7  42.3  51.2  25.4]\n",
            " [135.2  41.7  45.9  17.2]\n",
            " [222.4   4.3  49.8  16.7]\n",
            " [296.4  36.3 100.9  23.8]\n",
            " [280.2  10.1  21.4  19.8]\n",
            " [187.9  17.2  17.9  19.7]\n",
            " [238.2  34.3   5.3  20.7]\n",
            " [137.9  46.4  59.   15. ]\n",
            " [ 25.   11.   29.7   7.2]\n",
            " [ 90.4   0.3  23.2  12. ]\n",
            " [ 13.1   0.4  25.6   5.3]\n",
            " [255.4  26.9   5.5  19.8]\n",
            " [225.8   8.2  56.5  18.4]\n",
            " [241.7  38.   23.2  21.8]\n",
            " [175.7  15.4   2.4  17.1]\n",
            " [209.6  20.6  10.7  20.9]\n",
            " [ 78.2  46.8  34.5  14.6]\n",
            " [ 75.1  35.   52.7  12.6]\n",
            " [139.2  14.3  25.6  12.2]\n",
            " [ 76.4   0.8  14.8   9.4]\n",
            " [125.7  36.9  79.2  15.9]\n",
            " [ 19.4  16.   22.3   6.6]\n",
            " [141.3  26.8  46.2  15.5]\n",
            " [ 18.8  21.7  50.4   7. ]\n",
            " [224.    2.4  15.6  16.6]\n",
            " [123.1  34.6  12.4  15.2]\n",
            " [229.5  32.3  74.2  19.7]\n",
            " [ 87.2  11.8  25.9  10.6]\n",
            " [  7.8  38.9  50.6   6.6]\n",
            " [ 80.2   0.    9.2  11.9]\n",
            " [220.3  49.    3.2  24.7]\n",
            " [ 59.6  12.   43.1   9.7]\n",
            " [  0.7  39.6   8.7   1.6]\n",
            " [265.2   2.9  43.   17.7]\n",
            " [  8.4  27.2   2.1   5.7]\n",
            " [219.8  33.5  45.1  19.6]\n",
            " [ 36.9  38.6  65.6  10.8]\n",
            " [ 48.3  47.    8.5  11.6]\n",
            " [ 25.6  39.    9.3   9.5]\n",
            " [273.7  28.9  59.7  20.8]\n",
            " [ 43.   25.9  20.5   9.6]\n",
            " [184.9  43.9   1.7  20.7]\n",
            " [ 73.4  17.   12.9  10.9]\n",
            " [193.7  35.4  75.6  19.2]\n",
            " [220.5  33.2  37.9  20.1]\n",
            " [104.6   5.7  34.4  10.4]\n",
            " [ 96.2  14.8  38.9  12.3]\n",
            " [140.3   1.9   9.   10.3]\n",
            " [240.1   7.3   8.7  18.2]\n",
            " [243.2  49.   44.3  25.4]\n",
            " [ 38.   40.3  11.9  10.9]\n",
            " [ 44.7  25.8  20.6  10.1]\n",
            " [280.7  13.9  37.   16.1]\n",
            " [121.    8.4  48.7  11.6]\n",
            " [197.6  23.3  14.2  16.6]\n",
            " [171.3  39.7  37.7  16. ]\n",
            " [187.8  21.1   9.5  20.6]\n",
            " [  4.1  11.6   5.7   3.2]\n",
            " [ 93.9  43.5  50.5  15.3]\n",
            " [149.8   1.3  24.3  10.1]\n",
            " [ 11.7  36.9  45.2   7.3]\n",
            " [131.7  18.4  34.6  12.9]\n",
            " [172.5  18.1  30.7  16.4]\n",
            " [ 85.7  35.8  49.3  13.3]\n",
            " [188.4  18.1  25.6  19.9]\n",
            " [163.5  36.8   7.4  18. ]\n",
            " [117.2  14.7   5.4  11.9]\n",
            " [234.5   3.4  84.8  16.9]\n",
            " [ 17.9  37.6  21.6   8. ]\n",
            " [206.8   5.2  19.4  17.2]\n",
            " [215.4  23.6  57.6  17.1]\n",
            " [284.3  10.6   6.4  20. ]\n",
            " [ 50.   11.6  18.4   8.4]\n",
            " [164.5  20.9  47.4  17.5]\n",
            " [ 19.6  20.1  17.    7.6]\n",
            " [168.4   7.1  12.8  16.7]\n",
            " [222.4   3.4  13.1  16.5]\n",
            " [276.9  48.9  41.8  27. ]\n",
            " [248.4  30.2  20.3  20.2]\n",
            " [170.2   7.8  35.2  16.7]\n",
            " [276.7   2.3  23.7  16.8]\n",
            " [165.6  10.   17.6  17.6]\n",
            " [156.6   2.6   8.3  15.5]\n",
            " [218.5   5.4  27.4  17.2]\n",
            " [ 56.2   5.7  29.7   8.7]\n",
            " [287.6  43.   71.8  26.2]\n",
            " [253.8  21.3  30.   17.6]\n",
            " [205.   45.1  19.6  22.6]\n",
            " [139.5   2.1  26.6  10.3]\n",
            " [191.1  28.7  18.2  17.3]\n",
            " [286.   13.9   3.7  20.9]\n",
            " [ 18.7  12.1  23.4   6.7]\n",
            " [ 39.5  41.1   5.8  10.8]\n",
            " [ 75.5  10.8   6.   11.9]\n",
            " [ 17.2   4.1  31.6   5.9]\n",
            " [166.8  42.    3.6  19.6]\n",
            " [149.7  35.6   6.   17.3]\n",
            " [ 38.2   3.7  13.8   7.6]\n",
            " [ 94.2   4.9   8.1  14. ]\n",
            " [177.    9.3   6.4  14.8]\n",
            " [283.6  42.   66.2  25.5]\n",
            " [232.1   8.6   8.7  18.4]]\n",
            "[[230.1  37.8  69.2]\n",
            " [ 44.5  39.3  45.1]\n",
            " [ 17.2  45.9  69.3]\n",
            " [151.5  41.3  58.5]\n",
            " [180.8  10.8  58.4]\n",
            " [  8.7  48.9  75. ]\n",
            " [ 57.5  32.8  23.5]\n",
            " [120.2  19.6  11.6]\n",
            " [  8.6   2.1   1. ]\n",
            " [199.8   2.6  21.2]\n",
            " [ 66.1   5.8  24.2]\n",
            " [214.7  24.    4. ]\n",
            " [ 23.8  35.1  65.9]\n",
            " [ 97.5   7.6   7.2]\n",
            " [204.1  32.9  46. ]\n",
            " [195.4  47.7  52.9]\n",
            " [ 67.8  36.6 114. ]\n",
            " [281.4  39.6  55.8]\n",
            " [ 69.2  20.5  18.3]\n",
            " [147.3  23.9  19.1]\n",
            " [218.4  27.7  53.4]\n",
            " [237.4   5.1  23.5]\n",
            " [ 13.2  15.9  49.6]\n",
            " [228.3  16.9  26.2]\n",
            " [ 62.3  12.6  18.3]\n",
            " [262.9   3.5  19.5]\n",
            " [142.9  29.3  12.6]\n",
            " [240.1  16.7  22.9]\n",
            " [248.8  27.1  22.9]\n",
            " [ 70.6  16.   40.8]\n",
            " [292.9  28.3  43.2]\n",
            " [112.9  17.4  38.6]\n",
            " [ 97.2   1.5  30. ]\n",
            " [265.6  20.    0.3]\n",
            " [ 95.7   1.4   7.4]\n",
            " [290.7   4.1   8.5]\n",
            " [266.9  43.8   5. ]\n",
            " [ 74.7  49.4  45.7]\n",
            " [ 43.1  26.7  35.1]\n",
            " [228.   37.7  32. ]\n",
            " [202.5  22.3  31.6]\n",
            " [177.   33.4  38.7]\n",
            " [293.6  27.7   1.8]\n",
            " [206.9   8.4  26.4]\n",
            " [ 25.1  25.7  43.3]\n",
            " [175.1  22.5  31.5]\n",
            " [ 89.7   9.9  35.7]\n",
            " [239.9  41.5  18.5]\n",
            " [227.2  15.8  49.9]\n",
            " [ 66.9  11.7  36.8]\n",
            " [199.8   3.1  34.6]\n",
            " [100.4   9.6   3.6]\n",
            " [216.4  41.7  39.6]\n",
            " [182.6  46.2  58.7]\n",
            " [262.7  28.8  15.9]\n",
            " [198.9  49.4  60. ]\n",
            " [  7.3  28.1  41.4]\n",
            " [136.2  19.2  16.6]\n",
            " [210.8  49.6  37.7]\n",
            " [210.7  29.5   9.3]\n",
            " [ 53.5   2.   21.4]\n",
            " [261.3  42.7  54.7]\n",
            " [239.3  15.5  27.3]\n",
            " [102.7  29.6   8.4]\n",
            " [131.1  42.8  28.9]\n",
            " [ 69.    9.3   0.9]\n",
            " [ 31.5  24.6   2.2]\n",
            " [139.3  14.5  10.2]\n",
            " [237.4  27.5  11. ]\n",
            " [216.8  43.9  27.2]\n",
            " [199.1  30.6  38.7]\n",
            " [109.8  14.3  31.7]\n",
            " [ 26.8  33.   19.3]\n",
            " [129.4   5.7  31.3]\n",
            " [213.4  24.6  13.1]\n",
            " [ 16.9  43.7  89.4]\n",
            " [ 27.5   1.6  20.7]\n",
            " [120.5  28.5  14.2]\n",
            " [  5.4  29.9   9.4]\n",
            " [116.    7.7  23.1]\n",
            " [ 76.4  26.7  22.3]\n",
            " [239.8   4.1  36.9]\n",
            " [ 75.3  20.3  32.5]\n",
            " [ 68.4  44.5  35.6]\n",
            " [213.5  43.   33.8]\n",
            " [193.2  18.4  65.7]\n",
            " [ 76.3  27.5  16. ]\n",
            " [110.7  40.6  63.2]\n",
            " [ 88.3  25.5  73.4]\n",
            " [109.8  47.8  51.4]\n",
            " [134.3   4.9   9.3]\n",
            " [ 28.6   1.5  33. ]\n",
            " [217.7  33.5  59. ]\n",
            " [250.9  36.5  72.3]\n",
            " [107.4  14.   10.9]\n",
            " [163.3  31.6  52.9]\n",
            " [197.6   3.5   5.9]\n",
            " [184.9  21.   22. ]\n",
            " [289.7  42.3  51.2]\n",
            " [135.2  41.7  45.9]\n",
            " [222.4   4.3  49.8]\n",
            " [296.4  36.3 100.9]\n",
            " [280.2  10.1  21.4]\n",
            " [187.9  17.2  17.9]\n",
            " [238.2  34.3   5.3]\n",
            " [137.9  46.4  59. ]\n",
            " [ 25.   11.   29.7]\n",
            " [ 90.4   0.3  23.2]\n",
            " [ 13.1   0.4  25.6]\n",
            " [255.4  26.9   5.5]\n",
            " [225.8   8.2  56.5]\n",
            " [241.7  38.   23.2]\n",
            " [175.7  15.4   2.4]\n",
            " [209.6  20.6  10.7]\n",
            " [ 78.2  46.8  34.5]\n",
            " [ 75.1  35.   52.7]\n",
            " [139.2  14.3  25.6]\n",
            " [ 76.4   0.8  14.8]\n",
            " [125.7  36.9  79.2]\n",
            " [ 19.4  16.   22.3]\n",
            " [141.3  26.8  46.2]\n",
            " [ 18.8  21.7  50.4]\n",
            " [224.    2.4  15.6]\n",
            " [123.1  34.6  12.4]\n",
            " [229.5  32.3  74.2]\n",
            " [ 87.2  11.8  25.9]\n",
            " [  7.8  38.9  50.6]\n",
            " [ 80.2   0.    9.2]\n",
            " [220.3  49.    3.2]\n",
            " [ 59.6  12.   43.1]\n",
            " [  0.7  39.6   8.7]\n",
            " [265.2   2.9  43. ]\n",
            " [  8.4  27.2   2.1]\n",
            " [219.8  33.5  45.1]\n",
            " [ 36.9  38.6  65.6]\n",
            " [ 48.3  47.    8.5]\n",
            " [ 25.6  39.    9.3]\n",
            " [273.7  28.9  59.7]\n",
            " [ 43.   25.9  20.5]\n",
            " [184.9  43.9   1.7]\n",
            " [ 73.4  17.   12.9]\n",
            " [193.7  35.4  75.6]\n",
            " [220.5  33.2  37.9]\n",
            " [104.6   5.7  34.4]\n",
            " [ 96.2  14.8  38.9]\n",
            " [140.3   1.9   9. ]\n",
            " [240.1   7.3   8.7]\n",
            " [243.2  49.   44.3]\n",
            " [ 38.   40.3  11.9]\n",
            " [ 44.7  25.8  20.6]\n",
            " [280.7  13.9  37. ]\n",
            " [121.    8.4  48.7]\n",
            " [197.6  23.3  14.2]\n",
            " [171.3  39.7  37.7]\n",
            " [187.8  21.1   9.5]\n",
            " [  4.1  11.6   5.7]\n",
            " [ 93.9  43.5  50.5]\n",
            " [149.8   1.3  24.3]\n",
            " [ 11.7  36.9  45.2]\n",
            " [131.7  18.4  34.6]\n",
            " [172.5  18.1  30.7]\n",
            " [ 85.7  35.8  49.3]\n",
            " [188.4  18.1  25.6]\n",
            " [163.5  36.8   7.4]\n",
            " [117.2  14.7   5.4]\n",
            " [234.5   3.4  84.8]\n",
            " [ 17.9  37.6  21.6]\n",
            " [206.8   5.2  19.4]\n",
            " [215.4  23.6  57.6]\n",
            " [284.3  10.6   6.4]\n",
            " [ 50.   11.6  18.4]\n",
            " [164.5  20.9  47.4]\n",
            " [ 19.6  20.1  17. ]\n",
            " [168.4   7.1  12.8]\n",
            " [222.4   3.4  13.1]\n",
            " [276.9  48.9  41.8]\n",
            " [248.4  30.2  20.3]\n",
            " [170.2   7.8  35.2]\n",
            " [276.7   2.3  23.7]\n",
            " [165.6  10.   17.6]\n",
            " [156.6   2.6   8.3]\n",
            " [218.5   5.4  27.4]\n",
            " [ 56.2   5.7  29.7]\n",
            " [287.6  43.   71.8]\n",
            " [253.8  21.3  30. ]\n",
            " [205.   45.1  19.6]\n",
            " [139.5   2.1  26.6]\n",
            " [191.1  28.7  18.2]\n",
            " [286.   13.9   3.7]\n",
            " [ 18.7  12.1  23.4]\n",
            " [ 39.5  41.1   5.8]\n",
            " [ 75.5  10.8   6. ]\n",
            " [ 17.2   4.1  31.6]\n",
            " [166.8  42.    3.6]\n",
            " [149.7  35.6   6. ]\n",
            " [ 38.2   3.7  13.8]\n",
            " [ 94.2   4.9   8.1]\n",
            " [177.    9.3   6.4]\n",
            " [283.6  42.   66.2]\n",
            " [232.1   8.6   8.7]]\n",
            "[22.1 10.4 12.  16.5 17.9  7.2 11.8 13.2  4.8 15.6 12.6 17.4  9.2 13.7\n",
            " 19.  22.4 12.5 24.4 11.3 14.6 18.  17.5  5.6 20.5  9.7 17.  15.  20.9\n",
            " 18.9 10.5 21.4 11.9 13.2 17.4 11.9 17.8 25.4 14.7 10.1 21.5 16.6 17.1\n",
            " 20.7 17.9  8.5 16.1 10.6 23.2 19.8  9.7 16.4 10.7 22.6 21.2 20.2 23.7\n",
            "  5.5 13.2 23.8 18.4  8.1 24.2 20.7 14.  16.  11.3 11.  13.4 18.9 22.3\n",
            " 18.3 12.4  8.8 11.  17.   8.7  6.9 14.2  5.3 11.  11.8 17.3 11.3 13.6\n",
            " 21.7 20.2 12.  16.  12.9 16.7 14.   7.3 19.4 22.2 11.5 16.9 16.7 20.5\n",
            " 25.4 17.2 16.7 23.8 19.8 19.7 20.7 15.   7.2 12.   5.3 19.8 18.4 21.8\n",
            " 17.1 20.9 14.6 12.6 12.2  9.4 15.9  6.6 15.5  7.  16.6 15.2 19.7 10.6\n",
            "  6.6 11.9 24.7  9.7  1.6 17.7  5.7 19.6 10.8 11.6  9.5 20.8  9.6 20.7\n",
            " 10.9 19.2 20.1 10.4 12.3 10.3 18.2 25.4 10.9 10.1 16.1 11.6 16.6 16.\n",
            " 20.6  3.2 15.3 10.1  7.3 12.9 16.4 13.3 19.9 18.  11.9 16.9  8.  17.2\n",
            " 17.1 20.   8.4 17.5  7.6 16.7 16.5 27.  20.2 16.7 16.8 17.6 15.5 17.2\n",
            "  8.7 26.2 17.6 22.6 10.3 17.3 20.9  6.7 10.8 11.9  5.9 19.6 17.3  7.6\n",
            " 14.  14.8 25.5 18.4]\n",
            "[[0.77631579 0.76209677 0.60701754]\n",
            " [0.15013495 0.79233871 0.39561404]\n",
            " [0.05802969 0.92540323 0.60789474]\n",
            " [0.5111336  0.83266129 0.51315789]\n",
            " [0.6099865  0.21774194 0.5122807 ]\n",
            " [0.02935223 0.9858871  0.65789474]\n",
            " [0.1939946  0.66129032 0.20614035]\n",
            " [0.40553306 0.39516129 0.10175439]\n",
            " [0.02901484 0.04233871 0.00877193]\n",
            " [0.67408907 0.05241935 0.18596491]\n",
            " [0.22300945 0.11693548 0.2122807 ]\n",
            " [0.72435897 0.48387097 0.03508772]\n",
            " [0.0802969  0.70766129 0.57807018]\n",
            " [0.32894737 0.15322581 0.06315789]\n",
            " [0.68859649 0.66330645 0.40350877]\n",
            " [0.65924426 0.96169355 0.46403509]\n",
            " [0.22874494 0.73790323 1.        ]\n",
            " [0.94939271 0.7983871  0.48947368]\n",
            " [0.23346829 0.41330645 0.16052632]\n",
            " [0.49696356 0.48185484 0.16754386]\n",
            " [0.73684211 0.55846774 0.46842105]\n",
            " [0.80094467 0.10282258 0.20614035]\n",
            " [0.04453441 0.32056452 0.43508772]\n",
            " [0.77024291 0.34072581 0.22982456]\n",
            " [0.21018893 0.25403226 0.16052632]\n",
            " [0.88697706 0.07056452 0.17105263]\n",
            " [0.48211876 0.59072581 0.11052632]\n",
            " [0.81005398 0.33669355 0.20087719]\n",
            " [0.83940621 0.54637097 0.20087719]\n",
            " [0.23819163 0.32258065 0.35789474]\n",
            " [0.98819163 0.57056452 0.37894737]\n",
            " [0.38090418 0.35080645 0.33859649]\n",
            " [0.32793522 0.03024194 0.26315789]\n",
            " [0.89608637 0.40322581 0.00263158]\n",
            " [0.32287449 0.02822581 0.06491228]\n",
            " [0.98076923 0.08266129 0.0745614 ]\n",
            " [0.90047233 0.88306452 0.04385965]\n",
            " [0.25202429 0.99596774 0.40087719]\n",
            " [0.14541161 0.53830645 0.30789474]\n",
            " [0.76923077 0.76008065 0.28070175]\n",
            " [0.68319838 0.44959677 0.27719298]\n",
            " [0.59716599 0.6733871  0.33947368]\n",
            " [0.99055331 0.55846774 0.01578947]\n",
            " [0.69804318 0.16935484 0.23157895]\n",
            " [0.08468286 0.51814516 0.37982456]\n",
            " [0.59075574 0.45362903 0.27631579]\n",
            " [0.30263158 0.19959677 0.31315789]\n",
            " [0.80937922 0.83669355 0.1622807 ]\n",
            " [0.76653171 0.31854839 0.4377193 ]\n",
            " [0.2257085  0.2358871  0.32280702]\n",
            " [0.67408907 0.0625     0.30350877]\n",
            " [0.33873144 0.19354839 0.03157895]\n",
            " [0.73009447 0.84072581 0.34736842]\n",
            " [0.61605938 0.93145161 0.51491228]\n",
            " [0.88630229 0.58064516 0.13947368]\n",
            " [0.67105263 0.99596774 0.52631579]\n",
            " [0.02462888 0.56653226 0.36315789]\n",
            " [0.45951417 0.38709677 0.14561404]\n",
            " [0.71120108 1.         0.33070175]\n",
            " [0.7108637  0.59475806 0.08157895]\n",
            " [0.18049933 0.04032258 0.1877193 ]\n",
            " [0.88157895 0.8608871  0.47982456]\n",
            " [0.80735493 0.3125     0.23947368]\n",
            " [0.34649123 0.59677419 0.07368421]\n",
            " [0.44230769 0.86290323 0.25350877]\n",
            " [0.23279352 0.1875     0.00789474]\n",
            " [0.1062753  0.49596774 0.01929825]\n",
            " [0.46997301 0.29233871 0.08947368]\n",
            " [0.80094467 0.55443548 0.09649123]\n",
            " [0.73144399 0.88508065 0.23859649]\n",
            " [0.6717274  0.61693548 0.33947368]\n",
            " [0.37044534 0.28830645 0.27807018]\n",
            " [0.09041835 0.66532258 0.16929825]\n",
            " [0.4365722  0.11491935 0.2745614 ]\n",
            " [0.71997301 0.49596774 0.11491228]\n",
            " [0.05701754 0.88104839 0.78421053]\n",
            " [0.09278003 0.03225806 0.18157895]\n",
            " [0.40654521 0.57459677 0.1245614 ]\n",
            " [0.01821862 0.60282258 0.08245614]\n",
            " [0.39136302 0.15524194 0.20263158]\n",
            " [0.25775978 0.53830645 0.19561404]\n",
            " [0.80904184 0.08266129 0.32368421]\n",
            " [0.25404858 0.40927419 0.28508772]\n",
            " [0.23076923 0.89717742 0.3122807 ]\n",
            " [0.72031039 0.86693548 0.29649123]\n",
            " [0.65182186 0.37096774 0.57631579]\n",
            " [0.2574224  0.55443548 0.14035088]\n",
            " [0.37348178 0.81854839 0.55438596]\n",
            " [0.29790823 0.5141129  0.64385965]\n",
            " [0.37044534 0.96370968 0.45087719]\n",
            " [0.45310391 0.09879032 0.08157895]\n",
            " [0.09649123 0.03024194 0.28947368]\n",
            " [0.73448043 0.67540323 0.51754386]\n",
            " [0.84649123 0.7358871  0.63421053]\n",
            " [0.36234818 0.28225806 0.09561404]\n",
            " [0.55094467 0.63709677 0.46403509]\n",
            " [0.66666667 0.07056452 0.05175439]\n",
            " [0.62381916 0.4233871  0.19298246]\n",
            " [0.97739541 0.85282258 0.44912281]\n",
            " [0.45614035 0.84072581 0.40263158]\n",
            " [0.75033738 0.08669355 0.43684211]\n",
            " [1.         0.73185484 0.88508772]\n",
            " [0.94534413 0.20362903 0.1877193 ]\n",
            " [0.63394062 0.34677419 0.15701754]\n",
            " [0.80364372 0.69153226 0.04649123]\n",
            " [0.46524966 0.93548387 0.51754386]\n",
            " [0.08434548 0.22177419 0.26052632]\n",
            " [0.30499325 0.00604839 0.20350877]\n",
            " [0.04419703 0.00806452 0.2245614 ]\n",
            " [0.86167341 0.54233871 0.04824561]\n",
            " [0.76180837 0.16532258 0.49561404]\n",
            " [0.81545209 0.76612903 0.20350877]\n",
            " [0.59278003 0.31048387 0.02105263]\n",
            " [0.7071525  0.41532258 0.09385965]\n",
            " [0.26383266 0.94354839 0.30263158]\n",
            " [0.25337382 0.70564516 0.4622807 ]\n",
            " [0.46963563 0.28830645 0.2245614 ]\n",
            " [0.25775978 0.01612903 0.12982456]\n",
            " [0.42408907 0.74395161 0.69473684]\n",
            " [0.06545209 0.32258065 0.19561404]\n",
            " [0.47672065 0.54032258 0.40526316]\n",
            " [0.0634278  0.4375     0.44210526]\n",
            " [0.75573549 0.0483871  0.13684211]\n",
            " [0.41531714 0.69758065 0.10877193]\n",
            " [0.7742915  0.65120968 0.65087719]\n",
            " [0.29419703 0.23790323 0.22719298]\n",
            " [0.02631579 0.78427419 0.44385965]\n",
            " [0.2705803  0.         0.08070175]\n",
            " [0.74325236 0.98790323 0.02807018]\n",
            " [0.20107962 0.24193548 0.37807018]\n",
            " [0.00236167 0.7983871  0.07631579]\n",
            " [0.89473684 0.05846774 0.37719298]\n",
            " [0.02834008 0.5483871  0.01842105]\n",
            " [0.74156545 0.67540323 0.39561404]\n",
            " [0.12449393 0.77822581 0.5754386 ]\n",
            " [0.16295547 0.94758065 0.0745614 ]\n",
            " [0.08636977 0.78629032 0.08157895]\n",
            " [0.9234143  0.58266129 0.52368421]\n",
            " [0.14507422 0.52217742 0.17982456]\n",
            " [0.62381916 0.88508065 0.01491228]\n",
            " [0.24763833 0.34274194 0.11315789]\n",
            " [0.65350877 0.71370968 0.66315789]\n",
            " [0.74392713 0.66935484 0.33245614]\n",
            " [0.35290148 0.11491935 0.30175439]\n",
            " [0.3245614  0.2983871  0.34122807]\n",
            " [0.47334683 0.03830645 0.07894737]\n",
            " [0.81005398 0.14717742 0.07631579]\n",
            " [0.82051282 0.98790323 0.38859649]\n",
            " [0.12820513 0.8125     0.10438596]\n",
            " [0.15080972 0.52016129 0.18070175]\n",
            " [0.94703104 0.28024194 0.3245614 ]\n",
            " [0.40823212 0.16935484 0.42719298]\n",
            " [0.66666667 0.46975806 0.1245614 ]\n",
            " [0.57793522 0.80040323 0.33070175]\n",
            " [0.63360324 0.42540323 0.08333333]\n",
            " [0.01383266 0.23387097 0.05      ]\n",
            " [0.31680162 0.87701613 0.44298246]\n",
            " [0.50539811 0.02620968 0.21315789]\n",
            " [0.03947368 0.74395161 0.39649123]\n",
            " [0.44433198 0.37096774 0.30350877]\n",
            " [0.58198381 0.36491935 0.26929825]\n",
            " [0.2891363  0.72177419 0.43245614]\n",
            " [0.63562753 0.36491935 0.2245614 ]\n",
            " [0.55161943 0.74193548 0.06491228]\n",
            " [0.39541161 0.29637097 0.04736842]\n",
            " [0.79116059 0.06854839 0.74385965]\n",
            " [0.06039136 0.75806452 0.18947368]\n",
            " [0.6977058  0.10483871 0.17017544]\n",
            " [0.72672065 0.47580645 0.50526316]\n",
            " [0.95917679 0.21370968 0.05614035]\n",
            " [0.16869096 0.23387097 0.16140351]\n",
            " [0.55499325 0.42137097 0.41578947]\n",
            " [0.06612686 0.40524194 0.14912281]\n",
            " [0.56815115 0.14314516 0.1122807 ]\n",
            " [0.75033738 0.06854839 0.11491228]\n",
            " [0.93421053 0.9858871  0.36666667]\n",
            " [0.83805668 0.60887097 0.17807018]\n",
            " [0.57422402 0.15725806 0.30877193]\n",
            " [0.93353576 0.04637097 0.20789474]\n",
            " [0.55870445 0.2016129  0.15438596]\n",
            " [0.52834008 0.05241935 0.07280702]\n",
            " [0.73717949 0.10887097 0.24035088]\n",
            " [0.18960864 0.11491935 0.26052632]\n",
            " [0.97031039 0.86693548 0.62982456]\n",
            " [0.8562753  0.42943548 0.26315789]\n",
            " [0.69163293 0.90927419 0.17192982]\n",
            " [0.47064777 0.04233871 0.23333333]\n",
            " [0.64473684 0.57862903 0.15964912]\n",
            " [0.96491228 0.28024194 0.03245614]\n",
            " [0.06309042 0.24395161 0.20526316]\n",
            " [0.13326586 0.82862903 0.05087719]\n",
            " [0.25472335 0.21774194 0.05263158]\n",
            " [0.05802969 0.08266129 0.27719298]\n",
            " [0.56275304 0.84677419 0.03157895]\n",
            " [0.50506073 0.71774194 0.05263158]\n",
            " [0.12887989 0.07459677 0.12105263]\n",
            " [0.31781377 0.09879032 0.07105263]\n",
            " [0.59716599 0.1875     0.05614035]\n",
            " [0.95681511 0.84677419 0.58070175]\n",
            " [0.78306343 0.1733871  0.07631579]]\n",
            "(200, 3)\n",
            "Epoch 100, Loss: 27.656756584048438\n",
            "Epoch 200, Loss: 10.60568214103228\n",
            "Epoch 300, Loss: 8.41124143746471\n",
            "Epoch 400, Loss: 7.623647629703028\n",
            "Epoch 500, Loss: 7.1202303610092095\n",
            "Epoch 600, Loss: 6.763623382428791\n",
            "Epoch 700, Loss: 6.507713896419295\n",
            "Epoch 800, Loss: 6.323598866204691\n",
            "Epoch 900, Loss: 6.190918213131104\n",
            "Epoch 1000, Loss: 6.095126336370854\n",
            "Epoch 1100, Loss: 6.025812975865199\n",
            "Epoch 1200, Loss: 5.975523909888625\n",
            "Epoch 1300, Loss: 5.938919385389845\n",
            "Epoch 1400, Loss: 5.912172469805341\n",
            "Epoch 1500, Loss: 5.892538814896657\n",
            "Epoch 1600, Loss: 5.878048965709273\n",
            "Epoch 1700, Loss: 5.867288287741592\n",
            "Epoch 1800, Loss: 5.859239542969861\n",
            "Epoch 1900, Loss: 5.853170263345998\n",
            "Epoch 2000, Loss: 5.8485521589636615\n",
            "Epoch 2100, Loss: 5.845003435930223\n",
            "Epoch 2200, Loss: 5.842247499716293\n",
            "Epoch 2300, Loss: 5.840083379070979\n",
            "Epoch 2400, Loss: 5.838364534873206\n",
            "Epoch 2500, Loss: 5.836983668651767\n",
            "Epoch 2600, Loss: 5.835861824978097\n",
            "Epoch 2700, Loss: 5.83494056774463\n",
            "Epoch 2800, Loss: 5.834176357698027\n",
            "Epoch 2900, Loss: 5.833536506969092\n",
            "Epoch 3000, Loss: 5.832996263946699\n",
            "Epoch 3100, Loss: 5.83253670885274\n",
            "Epoch 3200, Loss: 5.8321432312104955\n",
            "Epoch 3300, Loss: 5.831804425369308\n",
            "Epoch 3400, Loss: 5.831511286725001\n",
            "Epoch 3500, Loss: 5.8312566245275494\n",
            "Epoch 3600, Loss: 5.8310346309626695\n",
            "Epoch 3700, Loss: 5.830840563225918\n",
            "Epoch 3800, Loss: 5.830670507502362\n",
            "Epoch 3900, Loss: 5.830521202499291\n",
            "Epoch 4000, Loss: 5.830389906438055\n",
            "Epoch 4100, Loss: 5.8302742958985325\n",
            "Stopping at epoch 4165, Loss: 5.830206609005456, Change in loss: 9.999897319090678e-07\n",
            "[23.48077449 10.56730622 10.50699537 18.45248462 15.56673874 10.58376827\n",
            "  9.7628148  11.51223234  0.93957526 14.429932    6.07010925 18.31636449\n",
            "  9.13211907  7.95393258 20.26999318 22.24383675 13.74960331 26.80496288\n",
            "  8.43774408 14.23420316 20.62208405 17.41465611  4.88645596 18.76008827\n",
            "  6.72032728 18.74984852 14.60393956 19.42068046 21.65588725  8.48611426\n",
            " 25.40517124 11.47705326  7.6431298  20.98090095  6.85424482 20.38036904\n",
            " 24.98915329 14.21313975  8.17407876 22.21724333 18.05019307 18.31658876\n",
            " 24.12481452 15.981839    7.05325909 16.2432744   8.64484168 23.21652934\n",
            " 19.21685959  7.43602242 14.90811097  8.35885609 22.30174132 21.32054647\n",
            " 22.64894184 22.95969182  6.18548174 12.66941711 23.12515749 19.07991669\n",
            "  4.53889096 25.91811242 19.30735859 11.83334421 16.44326382  6.12714279\n",
            "  6.08427339 11.93993772 20.60156752 22.30908884 19.35236434 10.57151895\n",
            "  7.61280343 10.50640607 18.59538129 10.73547421  2.71258723 13.02371431\n",
            "  5.39195334  9.68239713 10.02419398 17.81531074  9.2371956  12.71201282\n",
            " 22.1414026  17.82219973  9.95712952 15.74764763 12.15137271 16.48014372\n",
            " 10.05294141  3.13640367 21.66331689 24.76001694  9.74412308 17.53529407\n",
            " 13.97025121 16.37883935 27.65312834 17.04904975 17.0651996  28.62764806\n",
            " 21.01403059 15.85409101 21.56592324 18.36648187  4.30635953  6.79455061\n",
            "  1.7029841  21.54852528 18.11198419 22.92090705 14.2895176  17.63386392\n",
            " 13.70127105 12.16039034 12.35971571  5.6860749  16.64086132  4.5053672\n",
            " 15.0993744   6.20693789 15.85284693 14.11350115 22.71553006  8.48760181\n",
            "  8.20862587  5.64692354 22.63969593  7.18207481  6.59735553 19.50789747\n",
            "  4.94674948 21.3903924  10.55692664 10.95616104  8.18810873 24.70514084\n",
            "  7.60582859 19.4130875   8.00237189 20.851218   21.17537857  8.93712552\n",
            "  9.95404671  9.96936216 17.50468069 25.39692867  9.30278092  7.7068114\n",
            " 22.11547069 10.89036873 17.36301902 18.90588124 16.21705969  2.28728746\n",
            " 14.70493392 10.96578472  7.99147178 12.77644873 15.34621295 12.89648856\n",
            " 16.25970651 17.02092952 10.34824678 18.77435816  7.81580972 15.25843229\n",
            " 19.89467077 20.92180685  5.74036135 15.75203253  5.01245641 12.79122052\n",
            " 15.83013805 27.56444899 22.04424322 13.68958015 19.60873195 13.20720764\n",
            " 11.15179875 16.31212685  5.55461274 28.23663748 21.28065184 21.48302667\n",
            " 10.47125825 17.9045071  21.47965654  3.87157692  9.34886305  6.95269991\n",
            "  2.74406129 17.95511054 15.86405735  3.55777824  7.33065245 13.52648394\n",
            " 27.64313365 17.17524603]\n",
            "[19.85791972  7.88035562  3.39226484]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbIQzYFmzBre"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}